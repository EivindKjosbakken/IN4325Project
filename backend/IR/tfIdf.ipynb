{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import numpy as np\n",
    "from nltk.tokenize import  word_tokenize \n",
    "from tqdm import tqdm\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read data in\n",
    "\n",
    "dfInventory = pd.read_excel(\"../data/inventory.xlsx\")\n",
    "dfRepo1 = pd.read_csv(\"../data/tudelft_repository_1679269258.csv\")\n",
    "dfRepo2 = pd.read_csv(\"../data/tudelft_repository_1679269271.csv\")\n",
    "dfRepo3 = pd.read_csv(\"../data/tudelft_repository_1679269276.csv\")\n",
    "dfRepo4 = pd.read_csv(\"../data/tudelft_repository_1679269281.csv\")\n",
    "dfRepo5 = pd.read_csv(\"../data/tudelft_repository_1679269287.csv\")\n",
    "dfRepo6 = pd.read_csv(\"../data/tudelft_repository_1679269292.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfRepo = pd.concat([dfRepo1, dfRepo2, dfRepo3, dfRepo4, dfRepo5, dfRepo6])\n",
    "dfWithAbstract = dfRepo.dropna(subset=[\"abstract\"]) #elements without abstract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Artificial Intelligence (AI) is increasingly helping people with all kinds of tasks, due to its promising capabilities. In some tasks, an AI system by itself will take over tasks, but in other tasks, an AI system making decisions on its own would be undesired due to ethical and legal reasons. In those cases, AI can still be of help by forming human-AI teams, in which humans get advice from the AI system helping them with making their final decisions. Human-AI teams are for instance used in the medical and legal fields. One problem arises, in which instances should one trust an AI system and in which not? Trusting the AI system when it is correct and trusting yourself when you are correct, results in a high appropriate reliance. If users appropriately rely on AI systems, it is possible to achieve complementary team performance, which is better than any single teammate. However, as known from previous literature, people struggle with assessing their performance and knowing how well they perform compared to peers. When one overestimates their performance this can be because of a dual burden, due to the lack of skill they also lack the skill to accurately estimate their performance. This phenomenon is called the Dunning-Kruger Effect (DKE). This raises questions about whether the inability to estimate their own capabilities would also reflect on their assessment of the AI system its performance.<br/><br/>In this thesis we look at how the DKE affects (appropriate) reliance on AI systems and if so, how such effects due to the DKE can be mitigated. The effects of the DKE and possible mitigation are being tested through an empirical study (N = 249). The attempt at mitigation is done by including a tutorial intervention, which has been proved in previous research to be useful in decreasing the DKE. The tutorial intervention is aimed at revealing the weaknesses of the participant and making them aware of their miscalibrated self-estimation. Furthermore, in this thesis, the effects of revealing how the AI system makes its decisions through explainable AI (XAI) are explored. The XAI consisted of highlights from logic unit-based explanations, it should allow participants to gain more understanding of the AI advice. This thesis shows how this will affect user self-assessment and reliance on the AI system.<br/><br/>We found that participants who overestimate themselves tend to rely less on the AI system, compared to participants that had an accurate or underestimation of their performance. After the tutorial participants have a better calibration of their self-assessment. While the designed tutorial intervention can help participants calibrate their self-assessment, it fails to promote (appropriate) reliance. Furthermore, the logic units-based explanations did not improve accurate self-assessing or increase user (appropriate) reliance on AI systems.<br/>This thesis shows the importance of considering cognitive biases when dealing with human-AI teams and invites more research on how to handle and mitigate the DKE in human-AI decision making.'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfWithAbstract.iloc[855,6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#implement tf-idf:\n",
    "\n",
    "npWithAbstract = dfWithAbstract.to_numpy()[:1000, :] #NOTE: only taking 1k first rows for now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tf-idf with sklearn\n",
    "allAbstracts = npWithAbstract[:, 6]\n",
    "corpus = allAbstracts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfIdfVectorizer=TfidfVectorizer(use_idf=True)\n",
    "tfIdfMatrix = tfIdfVectorizer.fit_transform(corpus) #this is the matrix\n",
    "df = pd.DataFrame(tfIdfMatrix[0].T.todense(), index=tfIdfVectorizer.get_feature_names_out(), columns=[\"TF-IDF\"])\n",
    "df = df.sort_values('TF-IDF', ascending=False)\n",
    "tfIdfMatrix =  tfIdfMatrix.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "uniqueWords = tfIdfVectorizer.get_feature_names_out() #unique words\n",
    "uniqueWordsIndexDict = dict()\n",
    "for idx, word in enumerate(uniqueWords):\n",
    "    uniqueWordsIndexDict[word] = idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "invDocFreq = dict.fromkeys(uniqueWords, 0)\n",
    "numDocuments = len(corpus)\n",
    "\n",
    "for text in corpus:\n",
    "\n",
    "    tokens = set(text.split()) #unique\n",
    "    for token in tokens: \n",
    "        if (token in invDocFreq):\n",
    "            invDocFreq[token] += 1\n",
    "for key, value in invDocFreq.items():\n",
    "    invDocFreq[key] = np.log(numDocuments/(value+1)) \n",
    "\n",
    "avgDocFreq = np.mean(np.array(list(invDocFreq.values())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inference\n",
    "\n",
    "def executeQuery(query: str):\n",
    "\tquery = query.lower()\n",
    "\n",
    "\t#make new vector of the input query\n",
    "\tQ = np.zeros(len(uniqueWords)) \n",
    "\ttokens = query.split()\n",
    "\tcounter = Counter(tokens)\n",
    "\twords_count = len(tokens)\n",
    "\t#calculate tf-idf scores for the input query\n",
    "\tfor token in np.unique(tokens):\n",
    "\t\tif token not in uniqueWords: #cannot calc for word that does not exist\n",
    "\t\t\tprint(f\"word {token} does not exist in vocabulary\")\n",
    "\t\t\tcontinue\n",
    "\n",
    "\t\ttf = counter[token]/words_count\n",
    "\t\tidf = invDocFreq.get(token, avgDocFreq)\n",
    "\t\ttfIdf = tf*idf\n",
    "\t\t#find idx of word in the vector\n",
    "\t\tidx = uniqueWordsIndexDict.get(token, None)\n",
    "\t\tif (idx is None):\n",
    "\t\t\tcontinue\n",
    "\n",
    "\t\tQ[idx] = tfIdf  \n",
    "\n",
    "\t#compare the input query vector to the vectors of all documents in corpus\n",
    "\tres = []\n",
    "\tfor idx, doc in enumerate(tfIdfMatrix):\n",
    "\t\tcosineSim = np.dot(doc,Q)/(np.linalg.norm(doc)*np.linalg.norm(Q))\n",
    "\t\tres.append((idx, cosineSim))\n",
    "\tres = np.array(res)\n",
    "\n",
    "\t#sort the results\n",
    "\tres = res[res[:, 1].argsort()[::-1]]\n",
    "\n",
    "\t# if we want to return the actualy abstracts, then return this, else is returns the indices\n",
    "\t\"\"\"\n",
    "\torderedCorpusAccordingToQuery = []\n",
    "\tfor idx, cosineSim in res:\n",
    "\t\torderedCorpusAccordingToQuery.append((corpus[int(idx)]))\n",
    "\treturn orderedCorpusAccordingToQuery\n",
    "\t\"\"\"\n",
    "\n",
    "\treturn np.array(res)[:, 0]  #only return the indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word pytorch does not exist in vocabulary\n",
      "Artificial Intelligence (AI) is increasingly helping people with all kinds of tasks, due to its promising capabilities. In some tasks, an AI system by itself will take over tasks, but in other tasks, an AI system making decisions on its own would be undesired due to ethical and legal reasons. In those cases, AI can still be of help by forming human-AI teams, in which humans get advice from the AI system helping them with making their final decisions. Human-AI teams are for instance used in the medical and legal fields. One problem arises, in which instances should one trust an AI system and in which not? Trusting the AI system when it is correct and trusting yourself when you are correct, results in a high appropriate reliance. If users appropriately rely on AI systems, it is possible to achieve complementary team performance, which is better than any single teammate. However, as known from previous literature, people struggle with assessing their performance and knowing how well they perform compared to peers. When one overestimates their performance this can be because of a dual burden, due to the lack of skill they also lack the skill to accurately estimate their performance. This phenomenon is called the Dunning-Kruger Effect (DKE). This raises questions about whether the inability to estimate their own capabilities would also reflect on their assessment of the AI system its performance.<br/><br/>In this thesis we look at how the DKE affects (appropriate) reliance on AI systems and if so, how such effects due to the DKE can be mitigated. The effects of the DKE and possible mitigation are being tested through an empirical study (N = 249). The attempt at mitigation is done by including a tutorial intervention, which has been proved in previous research to be useful in decreasing the DKE. The tutorial intervention is aimed at revealing the weaknesses of the participant and making them aware of their miscalibrated self-estimation. Furthermore, in this thesis, the effects of revealing how the AI system makes its decisions through explainable AI (XAI) are explored. The XAI consisted of highlights from logic unit-based explanations, it should allow participants to gain more understanding of the AI advice. This thesis shows how this will affect user self-assessment and reliance on the AI system.<br/><br/>We found that participants who overestimate themselves tend to rely less on the AI system, compared to participants that had an accurate or underestimation of their performance. After the tutorial participants have a better calibration of their self-assessment. While the designed tutorial intervention can help participants calibrate their self-assessment, it fails to promote (appropriate) reliance. Furthermore, the logic units-based explanations did not improve accurate self-assessing or increase user (appropriate) reliance on AI systems.<br/>This thesis shows the importance of considering cognitive biases when dealing with human-AI teams and invites more research on how to handle and mitigate the DKE in human-AI decision making.\n",
      "Powerful predictive AI systems have demonstrated great potential in augmenting human decision-making. Recent empirical work has argued that the vision for optimal human-AI collaboration requires ‘appropriate reliance’ of humans on AI systems. However, accurately estimating the trustworthiness of AI advice at the instance level is quite challenging, especially in the absence of performance feedback pertaining to the AI system. In practice, the performance disparity of machine learning models on out-of-distribution data makes the dataset-specific performance feedback unreliable in human-AI collaboration. Inspired by existing literature on critical thinking and explanation-based human debugging, we propose the use of debugging an AI system as an intervention to foster appropriate reliance. In this paper, we explore whether a critical evaluation of AI performance within a debugging setting can better calibrate users’ assessment of an AI system and lead to more appropriate reliance. Through a quantitative empirical study (N = 234), we found that our proposed debugging intervention does not work as expected in facilitating appropriate reliance. Instead, we observe a decrease in reliance on the AI system after the intervention — potentially resulting from early exposure to the AI system’s weakness. We explored the dynamics of user confidence to help explain how inappropriate reliance patterns occur and found that human confidence is not independent of AI advice, which is potentially dangerous when trying to achieve appropriate reliance. Our findings have important implications for designing effective interventions to facilitate appropriate reliance and better human-AI collaboration\n",
      "Supporting designers working with AI is important, yet the tools they have at their disposal are in many ways not satisfactory. The aim of this project was to design a digital canvas tool which lets designers explore AI and ML, adopt the affordances that AI and ML as a design material give, and which can be used to map out and design integrated products, services and systems (iPSSs) by not just guiding the design process but by becoming an integral part of it.\n"
     ]
    }
   ],
   "source": [
    "results = executeQuery(\"AI in python with pytorch\") #results are a list of indices from most relvant to least relevant from the corpus\n",
    "\n",
    "\n",
    "numberOfDocumentsToShow = 3\n",
    "for i in range(numberOfDocumentsToShow):\n",
    "\tprint(dfWithAbstract.iloc[int(results[i]), 6])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OLD CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nabstractIndex = 6\\n\\nsentences = []\\nword_set = []\\n\\nfor i in tqdm(range(npWithAbstract.shape[0])):\\n    abstractText = npWithAbstract[i, abstractIndex]\\n    \\n    x = [i.lower() for  i in word_tokenize(abstractText) if i.isalpha()]\\n    sentences.append(x)\\n    for word in x:\\n        if word not in word_set:\\n            word_set.append(word)\\n\\n \\nword_set = set(word_set)\\n\\ntotal_documents = (npWithAbstract.shape[0])\\n \\n#Creating an index for each word in our vocab.\\nindex_dict = {} #Dictionary to store index for each word\\ni = 0\\nfor word in word_set:\\n    index_dict[word] = i\\n    i += 1\\n\\n#Create a count dictionary\\n \\ndef count_dict(sentences):\\n    word_count = {}\\n    for word in tqdm(word_set):\\n        word_count[word] = 0\\n        for sent in sentences:\\n            if word in sent:\\n                word_count[word] += 1\\n    return word_count\\n \\nword_count = count_dict(sentences)\\n\\ndef termfreq(document, word):\\n    N = len(document)\\n    occurance = len([token for token in document if token == word])\\n    return occurance/N\\n\\ndef inverse_doc_freq(word):\\n    try:\\n        word_occurance = word_count[word] + 1\\n    except:\\n        word_occurance = 1\\n    return np.log(total_documents/word_occurance)\\n\\ndef tf_idf(sentence):\\n    tf_idf_vec = np.zeros((len(word_set),))\\n    for word in sentence:\\n        tf = termfreq(sentence,word)\\n        idf = inverse_doc_freq(word)\\n         \\n        value = tf*idf\\n        tf_idf_vec[index_dict[word]] = value \\n    return tf_idf_vec\\n\\n\\nvectors = []\\nfor sent in tqdm(sentences):\\n    vec = tf_idf(sent)\\n    vectors.append(vec)\\n'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# manual tf-idf implementations\n",
    "#abstract is index number 6 on a row\n",
    "\"\"\"\n",
    "abstractIndex = 6\n",
    "\n",
    "sentences = []\n",
    "word_set = []\n",
    "\n",
    "for i in tqdm(range(npWithAbstract.shape[0])):\n",
    "    abstractText = npWithAbstract[i, abstractIndex]\n",
    "    \n",
    "    x = [i.lower() for  i in word_tokenize(abstractText) if i.isalpha()]\n",
    "    sentences.append(x)\n",
    "    for word in x:\n",
    "        if word not in word_set:\n",
    "            word_set.append(word)\n",
    "\n",
    " \n",
    "word_set = set(word_set)\n",
    "\n",
    "total_documents = (npWithAbstract.shape[0])\n",
    " \n",
    "#Creating an index for each word in our vocab.\n",
    "index_dict = {} #Dictionary to store index for each word\n",
    "i = 0\n",
    "for word in word_set:\n",
    "    index_dict[word] = i\n",
    "    i += 1\n",
    "\n",
    "#Create a count dictionary\n",
    " \n",
    "def count_dict(sentences):\n",
    "    word_count = {}\n",
    "    for word in tqdm(word_set):\n",
    "        word_count[word] = 0\n",
    "        for sent in sentences:\n",
    "            if word in sent:\n",
    "                word_count[word] += 1\n",
    "    return word_count\n",
    " \n",
    "word_count = count_dict(sentences)\n",
    "\n",
    "def termfreq(document, word):\n",
    "    N = len(document)\n",
    "    occurance = len([token for token in document if token == word])\n",
    "    return occurance/N\n",
    "\n",
    "def inverse_doc_freq(word):\n",
    "    try:\n",
    "        word_occurance = word_count[word] + 1\n",
    "    except:\n",
    "        word_occurance = 1\n",
    "    return np.log(total_documents/word_occurance)\n",
    "\n",
    "def tf_idf(sentence):\n",
    "    tf_idf_vec = np.zeros((len(word_set),))\n",
    "    for word in sentence:\n",
    "        tf = termfreq(sentence,word)\n",
    "        idf = inverse_doc_freq(word)\n",
    "         \n",
    "        value = tf*idf\n",
    "        tf_idf_vec[index_dict[word]] = value \n",
    "    return tf_idf_vec\n",
    "\n",
    "\n",
    "vectors = []\n",
    "for sent in tqdm(sentences):\n",
    "    vec = tf_idf(sent)\n",
    "    vectors.append(vec)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nquery = \"eindhoven cultural heritage\"\\n\\n\\nQ = np.zeros((17020)) # number of unique words\\ntokens = query.split()\\ncounter = Counter(tokens)\\nwords_count = len(tokens)\\nquery_weights = {}\\nfor token in np.unique(tokens):\\n    if token not in uniqueWords: #cannot calc for word that does not exist\\n        print(f\"word {token} does not exist in vocabulary\")\\n        continue\\n\\n    tf = counter[token]/words_count\\n    idf = invDocFreq.get(token, avgDocFreq)\\n    tfIdf = tf*idf\\n    #find idx of word in the vector\\n    idx = uniqueWordsIndexDict.get(token, None)\\n    if (idx is None):\\n        continue\\n\\n    Q[idx] = tfIdf  \\n\\n#do cosine sim between Q and all vectors in tfIdfMatrix\\n\\nres[res[:, 1].argsort()[::-1]]\\n\\n#now do cosine sim between all vectors and Q\\nres = []\\nfor idx, doc in enumerate(tfIdfMatrix):\\n    cosineSim = np.dot(doc,Q)/(np.linalg.norm(doc)*np.linalg.norm(Q))\\n    res.append((idx, cosineSim))\\nres = np.array(res)\\n# arr = tfIdfMatrix.flatten()\\n'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#inference with tf-idf\n",
    "#each word in the query has a value for each document, add up these values for all words in the query, and then sort after the values\n",
    "# -> convert the query to a vector, calc tf from the vector, and df from all documents\n",
    "\n",
    "\"\"\"\n",
    "query = \"eindhoven cultural heritage\"\n",
    "\n",
    "\n",
    "Q = np.zeros((17020)) # number of unique words\n",
    "tokens = query.split()\n",
    "counter = Counter(tokens)\n",
    "words_count = len(tokens)\n",
    "query_weights = {}\n",
    "for token in np.unique(tokens):\n",
    "    if token not in uniqueWords: #cannot calc for word that does not exist\n",
    "        print(f\"word {token} does not exist in vocabulary\")\n",
    "        continue\n",
    "\n",
    "    tf = counter[token]/words_count\n",
    "    idf = invDocFreq.get(token, avgDocFreq)\n",
    "    tfIdf = tf*idf\n",
    "    #find idx of word in the vector\n",
    "    idx = uniqueWordsIndexDict.get(token, None)\n",
    "    if (idx is None):\n",
    "        continue\n",
    "\n",
    "    Q[idx] = tfIdf  \n",
    "\n",
    "#do cosine sim between Q and all vectors in tfIdfMatrix\n",
    "\n",
    "res[res[:, 1].argsort()[::-1]]\n",
    "\n",
    "#now do cosine sim between all vectors and Q\n",
    "res = []\n",
    "for idx, doc in enumerate(tfIdfMatrix):\n",
    "    cosineSim = np.dot(doc,Q)/(np.linalg.norm(doc)*np.linalg.norm(Q))\n",
    "    res.append((idx, cosineSim))\n",
    "res = np.array(res)\n",
    "# arr = tfIdfMatrix.flatten()\n",
    "\"\"\"\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
